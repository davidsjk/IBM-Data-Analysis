#IMPORTING TOOLS (PANDAS, MATPLOTLIB, NUMPY, SEABORN, SKLEARN.Pipeline, SKLEARN.Preprocessing (polynomial features))

Let's see if this works

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
%matplotlib inline
from scipy import stats

#install the xlrd module:
!conda install -c anaconda xlrd --yes

#Load Exel
df_can = pd.read_excel('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DV0101EN/labs/Data_Files/Canada.xlsx',
                       sheet_name='Canada by Citizenship',
                       skiprows=range(20),
                       skipfooter=2)

#LOAD CSV

#load from online

file_name='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/coursera/project/kc_house_data_NaN.csv'
df=pd.read_csv(file_name)


#Load a table without a header
df=pd.read_csv(file_name, header = None)

# add header to table without header
1# create header list
headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
"drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
"num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
"peak-rpm","city-mpg","highway-mpg","price"]

#Add header while creating DF
headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]
df = pd.read_csv(filename, names = headers)

# add header to df
df.columns = headers



#SAVE CSV ( and others)

#download to local machine
df.to_csv("automobile.csv",index = False)




#DATA Wrangling


# Drop missing values along the column "price" as follows
df.dropna(subset=["price"], axis=0)

#Select the columns of a data frame
df[['length','compression-ratio']]

#Replace Missing Values with n
df = df.fillna(n) 

# replace "?" to NaN
df.replace("?", np.nan, inplace = True)

#Evaluate Missing Data
missing_data = df.isnull()
missing_data.head(5)

#Count missing values in each column
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("") 

#Calculate the average of the column
avg_norm_loss = df["normalized-losses"].astype("float").mean(axis=0)
print("Average of normalized-losses:", avg_norm_loss)

#Replace "NaN" by mean value in "normalized-losses" column
df["normalized-losses"].replace(np.nan, avg_norm_loss, inplace=True)

#replace the missing 'num-of-doors' values by the most frequent (‘four’ for this case)
df["num-of-doors"].replace(np.nan, "four", inplace=True)

#Drop whole row with NaN in "price" column
df.dropna(subset=["price"], axis=0, inplace=True)
## reset index, because we droped two rows
df.reset_index(drop=True, inplace=True)

#Convert data types to proper format
df[["bore", "stroke"]] = df[["bore", "stroke"]].astype("float")
df[["normalized-losses"]] = df[["normalized-losses"]].astype("int")
df[["price"]] = df[["price"]].astype("float")
df[["peak-rpm"]] = df[["peak-rpm"]].astype("float")

#Data Standardization
# #Convert mpg to L/100km by mathematical operation (235 divided by mpg)
df['city-L/100km'] = 235/df["city-mpg"]

#Data Normalization
## replace (original value) by (original value)/(maximum value)
df['length'] = df['length']/df['length'].max()
df['width'] = df['width']/df['width'].max()

#Binning
##Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis.
##Convert data to correct format
df["horsepower"]=df["horsepower"].astype(int, copy=True)
##Lets plot the histogram of horspower, to see what the distribution of horsepower looks like.
%matplotlib inline
import matplotlib as plt
from matplotlib import pyplot
plt.pyplot.hist(df["horsepower"])
## set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")
##Create BIN
bins = np.linspace(min(df["horsepower"]), max(df["horsepower"]), 4)
bins
##set group names:
group_names = ['Low', 'Medium', 'High']
##Cut
df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )
df[['horsepower','horsepower-binned']].head(20)
##Lets see the number of vehicles in each bin.
df["horsepower-binned"].value_counts()
##Plot Bin
%matplotlib inline
import matplotlib as plt
from matplotlib import pyplot
pyplot.bar(group_names, df["horsepower-binned"].value_counts())
## set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")
##Create histogram for Bin
%matplotlib inline
import matplotlib as plt
from matplotlib import pyplot
a = (0,1,2)
## draw historgram of attribute "horsepower" with bins = 3
plt.pyplot.hist(df["horsepower"], bins = 3)
## set x/y labels and plot title
plt.pyplot.xlabel("horsepower")
plt.pyplot.ylabel("count")
plt.pyplot.title("horsepower bins")


#Indicator Variable
##(An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning.
##get indicator variables and assign it to data frame "dummy_variable_1"
dummy_variable_1 = pd.get_dummies(df["fuel-type"])
dummy_variable_1.head()
##change column names for clarity
dummy_variable_1.rename(columns={'fuel-type-diesel':'gas', 'fuel-type-diesel':'diesel'}, inplace=True)
## merge data frame "df" and "dummy_variable_1" 
df = pd.concat([df, dummy_variable_1], axis=1)
##drop original column "fuel-type" from "df"
df.drop("fuel-type", axis = 1, inplace=True)




#DATA ANALYSIS

#Print entire dataframe
df

#Print the first n rows of dataframe
df.head(n)

#Print the last n rows of dataframe
df.tail(n)

#Find the names of the columns
df.columns

#Find data-type of each column
df.dtypes

#Get statistical summary of each column (Numeric type only)
df.describe()

#Describe all the columns in "df"
df.describe(include = "all")

#Describe columns with objects
df.describe(include=['object'])

#Describe select columns
df[['length','compression-ratio']].describe()

#Look at the info of "df"
df.info

$Get list of indicies 
df.index.values

#get the index and columns as lists
df_can.columns.tolist()
df_can.index.tolist()

print (type(df_can.columns.tolist()))
print (type(df_can.index.tolist()))

#Find the correlation between all variables
df.corr()

#Find correlation between certain columns
df[['bore','stroke' ,'compression-ratio','horsepower']].corr()

#Count the occurrence of variable in a column
df['drive-wheels'].value_counts()

#Make value count to a dataframe
df['drive-wheels'].value_counts().to_frame()

#Make/Save/Name Header/Name Index of a value count dataframe
## Make and Save
drive_wheels_counts = df['drive-wheels'].value_counts().to_frame()
##Rename Column
drive_wheels_counts.rename(columns={'drive-wheels': 'value_counts'}, inplace=True)
##Name index
drive_wheels_counts.index.name = 'drive-wheels'

#Calculate f the most common type:
df['num-of-doors'].value_counts().idxmax()

#Get list of unique variable
df['drive-wheels'].unique()

#Group By
##Make new DF with necessary columns
df_group_one = df[['drive-wheels','body-style','price']]
###Assign the group by column, and find the mean of each group.
df_group_one = df_group_one.groupby(['drive-wheels'],as_index=False).mean()
df_group_one

#Group By Multiple Variables
df_gptest = df[['drive-wheels','body-style','price']]
grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()
## Convert to a Pivot table
grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')


#Calculate the Pearson Correlation Coefficient and P-value
from scipy import stats
pearson_coef, p_value = stats.pearsonr(df['wheel-base'], df['price'])
print("The Pearson Correlation Coecient is", pearson_coef, " with a P-value of P =", p_value)


#ANOVA: Analysis of Variance
The Analysis of Variance (ANOVA) is a statistical method used to test whether there are significant
differences between the means of two or more groups. ANOVA returns two parameters:
F-test score: ANOVA assumes the means of all groups are the same, calculates how much the
actual means deviate from the assumption, and reports it as the F-test score. A larger score means
there is a larger difference between the means.
P-value: P-value tells how statistically significant is our calculated score value.
##Groupby different groups in the same variable
grouped_test2=df_gptest[['drive-wheels', 'price']].groupby(['drive-wheels'])
##We can obtain the values of the method group using the method "get_group".
grouped_test2.get_group('4wd')['price']
##ANOVA
f_val, p_val = stats.f_oneway(grouped_test2.get_group('fwd')['price'], grouped_test2.get_group('rwd')['price'], grouped_test2.get_group('4wd')['price'])  
print( "ANOVA results: F=", f_val, ", P =", p_val)



#DATA VISUALIZATION

#Scatter Plot 
##(good way to visualize Continuous numerical variables ["int64" or "float64”])
sns.regplot(x="engine-size", y="price", data=df)

#Scatter Plot starts with Y = 0
sns.regplot(x="engine-size", y="price", data=df)
plt.ylim(0,)

#Box Plot
##(good way to visualize categorical variables [“object" or "int64”])
sns.boxplot(x="body-style", y="price", data=df)

#Heat Map
##(heatmap plots the target variable proportional to colour with respect to two variables)
plt.pcolor(grouped_pivot, cmap='RdBu')
plt.colorbar()
plt.show()
###Label names
row_labels = grouped_pivot.columns.levels[1]
col_labels = grouped_pivot.index
##Move ticks and labels to the center
ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)
ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)
##Insert labels
ax.set_xticklabels(row_labels, minor=False)
ax.set_yticklabels(col_labels, minor=False)
##Rotate label if too long
plt.xticks(rotation=90)
g.colorbar(im)
##Show
plt.show()
